{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d7dbafb",
   "metadata": {},
   "source": [
    "# Libraries <a class=\"anchor\" id=\"section1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85ac1ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704ae072",
   "metadata": {},
   "source": [
    "# Data <a class=\"anchor\" id=\"section1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f44e8435",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71ea7717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>ranked</th>\n",
       "      <th>price in rupees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1655.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>134</td>\n",
       "      <td>10800000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>134</td>\n",
       "      <td>4800000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1112.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>242</td>\n",
       "      <td>8800000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>335</td>\n",
       "      <td>5100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>261</td>\n",
       "      <td>4100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12558</th>\n",
       "      <td>12558</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>134</td>\n",
       "      <td>9897000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12559</th>\n",
       "      <td>12559</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1275.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>276</td>\n",
       "      <td>4400000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12560</th>\n",
       "      <td>12560</td>\n",
       "      <td>P</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>252</td>\n",
       "      <td>7100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12561</th>\n",
       "      <td>12561</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>307</td>\n",
       "      <td>7200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12562</th>\n",
       "      <td>12562</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>435</td>\n",
       "      <td>2500000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12563 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0 area_type  availability  bedrooms  total_sqft  bath  \\\n",
       "0               0         B             1       3.0      1655.0   3.0   \n",
       "1               1         B             1       2.0      1102.0   2.0   \n",
       "2               2         B             0       2.0      1112.0   2.0   \n",
       "3               3         B             1       3.0      1450.0   3.0   \n",
       "4               4         B             1       2.0      1010.0   2.0   \n",
       "...           ...       ...           ...       ...         ...   ...   \n",
       "12558       12558         B             1       3.0      1720.0   3.0   \n",
       "12559       12559         B             0       3.0      1275.0   3.0   \n",
       "12560       12560         P             1       2.0      1550.0   2.0   \n",
       "12561       12561         B             1       3.0      1535.0   3.0   \n",
       "12562       12562         B             1       1.0       400.0   1.0   \n",
       "\n",
       "       balcony  ranked  price in rupees  \n",
       "0          1.0     134       10800000.0  \n",
       "1          1.0     134        4800000.0  \n",
       "2          1.0     242        8800000.0  \n",
       "3          3.0     335        5100000.0  \n",
       "4          1.0     261        4100000.0  \n",
       "...        ...     ...              ...  \n",
       "12558      3.0     134        9897000.0  \n",
       "12559      2.0     276        4400000.0  \n",
       "12560      1.0     252        7100000.0  \n",
       "12561      1.0     307        7200000.0  \n",
       "12562      1.0     435        2500000.0  \n",
       "\n",
       "[12563 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a20eec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete uneeded columns\n",
    "del data['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d529d03",
   "metadata": {},
   "source": [
    "# Data Structure For Implementing The Algorithms <a class=\"anchor\" id=\"section1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8deda154",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, classASize, classBSize, pathValue1, pathValue2, score, df, feature):\n",
    "        self.classASize = classASize\n",
    "        self.classBSize = classBSize\n",
    "        self.pathValue1 = pathValue1\n",
    "        self.pathValue2 = pathValue2\n",
    "        self.score = score\n",
    "        self.df = df\n",
    "        self.feature = feature\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "class BinaryTree(object):\n",
    "    def __init__(self, classASize, classBSize, pathValue1, pathValue2, score, df, feature):\n",
    "        self.root = Node(classASize, classBSize, pathValue1, pathValue2, score, df, feature)         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5210ecd3",
   "metadata": {},
   "source": [
    "# Classification: Decision Tree & AdaBoost <a class=\"anchor\" id=\"section1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095b3750",
   "metadata": {},
   "source": [
    "### Gini Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00a76f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate weighted gini score for nodes with left and right nodes\n",
    "def calcGiniCategorical(leftNode, rightNode):   \n",
    "    leftNode_total = leftNode.classASize + leftNode.classBSize\n",
    "    rightNode_total = rightNode.classASize + rightNode.classBSize\n",
    "    \n",
    "    #avoiding division by 0\n",
    "    if leftNode_total == 0 or rightNode_total == 0:\n",
    "        return -1\n",
    "    \n",
    "    gini_left = 1 - pow(leftNode.classASize / leftNode_total, 2) - pow(leftNode.classBSize / leftNode_total, 2)\n",
    "    gini_right = 1 - pow(rightNode.classASize / rightNode_total, 2) - pow(rightNode.classBSize / rightNode_total, 2)\n",
    "    \n",
    "    total = leftNode_total + rightNode_total\n",
    "    \n",
    "    weighted_gini = (leftNode_total / total) * gini_left + (rightNode_total / total) * gini_right\n",
    "        \n",
    "    return weighted_gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "548e0fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate gini score for internal nodes, NOTE: this is not the weighted average \n",
    "def calcGiniOneNodeCategorical(node):   \n",
    "    node_size = node.classASize + node.classBSize\n",
    "    \n",
    "    #avoiding division by 0\n",
    "    if node_size == 0:\n",
    "        return -1\n",
    "    else:\n",
    "        gini_score = 1 - pow(node.classASize / node_size, 2) - pow(node.classBSize / node_size, 2)\n",
    "            \n",
    "    return gini_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e972940",
   "metadata": {},
   "source": [
    "### Performance Say Function For AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71759c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function calculates the performance say for each given stump\n",
    "def calcPerformanceSay(node):\n",
    "    left_A_Size = node.left.classASize\n",
    "    left_B_Size = node.left.classBSize\n",
    "    \n",
    "    right_A_Size = node.right.classASize\n",
    "    right_B_Size = node.right.classBSize\n",
    "    \n",
    "    overall_size = left_A_Size + left_B_Size + right_A_Size + right_B_Size\n",
    "    \n",
    "    total_error = 0\n",
    "    \n",
    "    if left_A_Size < left_B_Size:\n",
    "        total_error = total_error + (left_A_Size / overall_size)\n",
    "    else:\n",
    "        total_error = total_error + (left_B_Size / overall_size)\n",
    "        \n",
    "    if right_A_Size < right_B_Size:\n",
    "        total_error = total_error + (right_A_Size / overall_size)\n",
    "    else:\n",
    "        total_error = total_error + (right_B_Size / overall_size)\n",
    "        \n",
    "    perf_say = 0.5 * np.log((1 - total_error) / total_error)\n",
    "    \n",
    "    return perf_say"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05011500",
   "metadata": {},
   "source": [
    "### Consecutive Averages Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b9ec002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consecutive_avgs(data):\n",
    "    # Python code to find average of each consecutive segment\n",
    "  \n",
    "    # Defining Splits\n",
    "    splits = 2\n",
    "  \n",
    "    # Finding average of each consecutive segment\n",
    "    Output = [sum(data[i:i + splits])/splits\n",
    "              for i in range(len(data) - splits + 1)]\n",
    "  \n",
    "    return Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44243e95",
   "metadata": {},
   "source": [
    "### Classification Tree & AdaBoost Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e964b41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class classification_Tree(object):  \n",
    "    def __init__(self, max_depth = None, min_samples_split = 2, target_feature = None, features = None):\n",
    "        self.max_depth = 6 if max_depth is None else max_depth\n",
    "        self.min_samples_split = 2 if min_samples_split is None else min_samples_split\n",
    "        self.target_feature = None if target_feature is None else target_feature\n",
    "        self.features = features\n",
    " \n",
    "    # replace None values with 0, else return the value\n",
    "    def checkNone(self, values_list, val):\n",
    "        if val not in values_list.index.values:\n",
    "            return 0\n",
    "        return values_list[val]\n",
    "    \n",
    "    # split the data for each feature and return the best split with lowest Gini value\n",
    "    def best_split(self, df):  \n",
    "        # main stump that will contain the best split\n",
    "        main_tree = BinaryTree(None, None, None, None, None, None, None)\n",
    "\n",
    "        # this list stores all features with thier lowest gini value\n",
    "        gini_list = {}\n",
    "        \n",
    "        target_feat_vals = data[self.target_feature].unique()\n",
    "        target_feat_vals.sort()\n",
    "        \n",
    "        # iterate through the features to calculate gini value\n",
    "        for feature in list(self.features.keys()):\n",
    "            tree = BinaryTree(None,None, None, None, None, None, feature)\n",
    "            mini_df = df.loc[:, [self.target_feature, feature]]\n",
    "            if df[feature] is None:\n",
    "                continue\n",
    "            if self.features[feature]: \n",
    "                feat_vals = data[feature].unique()\n",
    "                feat_vals.sort()\n",
    "                if (mini_df[(mini_df[feature] == feat_vals[0])]).empty or (mini_df[(mini_df[feature] == feat_vals[1])]).empty:\n",
    "                    continue\n",
    "                \n",
    "                df_filtered_classA = mini_df[(mini_df[feature] == feat_vals[0])]\n",
    "                df_filtered_classB = mini_df[(mini_df[feature] == feat_vals[1])] \n",
    "                \n",
    "                filtered_classA_byTarget = df_filtered_classA[self.target_feature].value_counts()\n",
    "                filtered_classB_byTarget = df_filtered_classB[self.target_feature].value_counts()\n",
    "                \n",
    "                tree.root.left = Node(self.checkNone(filtered_classA_byTarget, target_feat_vals[0]), self.checkNone(filtered_classA_byTarget, target_feat_vals[1]), None, None, None, df_filtered_classA, feature)\n",
    "                tree.root.right = Node(self.checkNone(filtered_classB_byTarget, target_feat_vals[0]), self.checkNone(filtered_classB_byTarget, target_feat_vals[1]), None, None, None, df_filtered_classB, feature)\n",
    "   \n",
    "                tree.root.left.gini_score = calcGiniOneNodeCategorical(tree.root.left)\n",
    "                tree.root.right.gini_score = calcGiniOneNodeCategorical(tree.root.right)\n",
    "            \n",
    "                if feature not in gini_list:\n",
    "                    gini_list[feature] = list()\n",
    "                    gini_list[feature].extend([calcGiniCategorical(tree.root.left, tree.root.right)])\n",
    "\n",
    "            else:\n",
    "                selected_col = df.loc[:, feature]\n",
    "                unique_vals = selected_col.unique()\n",
    "                sorted_vals = np.sort(unique_vals)\n",
    "                avg_list = consecutive_avgs(sorted_vals)\n",
    "                continuous_gini_list = {}\n",
    "                 \n",
    "                if len(avg_list) > 0:     \n",
    "                    for i in avg_list:   \n",
    "                        if (mini_df[(mini_df[feature] < i)]).empty or (mini_df[(mini_df[feature] > i)]).empty:\n",
    "                            continue\n",
    "                \n",
    "                        df_filtered_classA = mini_df[(mini_df[feature] < i)]\n",
    "                        df_filtered_classB = mini_df[(mini_df[feature] > i)]\n",
    "       \n",
    "                        filtered_classA_byTarget = df_filtered_classA[self.target_feature].value_counts()\n",
    "                        filtered_classB_byTarget = df_filtered_classB[self.target_feature].value_counts()\n",
    "            \n",
    "                        tree.root.left = Node(self.checkNone(filtered_classA_byTarget, target_feat_vals[0]), self.checkNone(filtered_classA_byTarget, target_feat_vals[1]), None, None, None, df_filtered_classA, feature)\n",
    "                        tree.root.right = Node(self.checkNone(filtered_classB_byTarget, target_feat_vals[0]), self.checkNone(filtered_classB_byTarget, target_feat_vals[1]), None, None, None, df_filtered_classB, feature)\n",
    "   \n",
    "                        continuous_gini_list[i] = calcGiniCategorical(tree.root.left, tree.root.right)\n",
    "        \n",
    "                    min_gini_index = min(continuous_gini_list, key=continuous_gini_list.get)\n",
    "\n",
    "                    if feature not in gini_list:\n",
    "                        gini_list[feature] = list()\n",
    "                        gini_list[feature].extend([min_gini_index, continuous_gini_list[min_gini_index]])\n",
    "                \n",
    "        min_gini = 999\n",
    "        min_gini_feature = None\n",
    "        \n",
    "        # find the lowest gini value and its feature\n",
    "        for k, v in gini_list.items():\n",
    "            if not self.features[k]:\n",
    "                if v[1] != -1:\n",
    "                    if v[1] < min_gini:\n",
    "                        min_gini = v[1]\n",
    "                        min_gini_feature = k\n",
    "            else:\n",
    "                if v[0] != -1:\n",
    "                    if v[0] < min_gini:\n",
    "                        min_gini = v[0]\n",
    "                        min_gini_feature = k\n",
    "        \n",
    "\n",
    "        # make sure gini values are between 0 and 1\n",
    "        if (min_gini < 0) or (min_gini > 1):\n",
    "            return None\n",
    "        \n",
    "        # create the tree with 2 nodes(stump) base on the feature with lowest gini value\n",
    "        if self.features[min_gini_feature]:\n",
    "            feat_vals = data[min_gini_feature].unique()\n",
    "            feat_vals.sort()\n",
    "            filtered_class_byTarget = df[self.target_feature].value_counts()\n",
    "            \n",
    "            main_tree.root = Node(self.checkNone(filtered_class_byTarget, target_feat_vals[0]), self.checkNone(filtered_class_byTarget, target_feat_vals[1]), feat_vals[0], feat_vals[1], gini_list[min_gini_feature][0], df, min_gini_feature)\n",
    "           \n",
    "            father_df = main_tree.root.df\n",
    "            if (father_df[father_df[main_tree.root.feature] == main_tree.root.pathValue1]).empty or (father_df[father_df[main_tree.root.feature] == main_tree.root.pathValue2]).empty:\n",
    "                return None\n",
    "            \n",
    "            leftNode_df = father_df[father_df[main_tree.root.feature] == main_tree.root.pathValue1]\n",
    "            rightNode_df = father_df[father_df[main_tree.root.feature] == main_tree.root.pathValue2]\n",
    "\n",
    "            main_tree.root.left = Node(self.checkNone(leftNode_df[self.target_feature].value_counts(), target_feat_vals[0]), self.checkNone(leftNode_df[self.target_feature].value_counts(), target_feat_vals[1]), None, None, None, leftNode_df, None)\n",
    "            main_tree.root.right = Node(self.checkNone(rightNode_df[self.target_feature].value_counts(), target_feat_vals[0]), self.checkNone(rightNode_df[self.target_feature].value_counts(), target_feat_vals[1]), None, None, None, rightNode_df, None)\n",
    "        else:  \n",
    "            filtered_class_byTarget = df[self.target_feature].value_counts()\n",
    "            \n",
    "            main_tree.root = Node(self.checkNone(filtered_class_byTarget, target_feat_vals[0]), self.checkNone(filtered_class_byTarget, target_feat_vals[1]), (-1 * gini_list[min_gini_feature][0]), gini_list[min_gini_feature][0], gini_list[min_gini_feature][1], df, min_gini_feature)\n",
    "           \n",
    "            father_df = main_tree.root.df\n",
    "            if (father_df[father_df[main_tree.root.feature] < abs(main_tree.root.pathValue1)]).empty or (father_df[father_df[main_tree.root.feature] > main_tree.root.pathValue2]).empty:\n",
    "                return None\n",
    "            \n",
    "            leftNode_df = father_df[father_df[main_tree.root.feature] < abs(main_tree.root.pathValue1)]\n",
    "            rightNode_df = father_df[father_df[main_tree.root.feature] > main_tree.root.pathValue2]\n",
    "\n",
    "            main_tree.root.left = Node(self.checkNone(leftNode_df[self.target_feature].value_counts(), target_feat_vals[0]), self.checkNone(leftNode_df[self.target_feature].value_counts(), target_feat_vals[1]), None, None, None, leftNode_df, None)\n",
    "            main_tree.root.right = Node(self.checkNone(rightNode_df[self.target_feature].value_counts(), target_feat_vals[0]), self.checkNone(rightNode_df[self.target_feature].value_counts(), target_feat_vals[1]), None, None, None, rightNode_df, None)\n",
    "   \n",
    "        # if the weighted gini value is bigger than the normal gini value then return None\n",
    "        if main_tree.root.score > calcGiniOneNodeCategorical(main_tree.root):\n",
    "            return None\n",
    "        return main_tree.root\n",
    "            \n",
    "\n",
    "    # recursive function to build the tree with each best split\n",
    "    def add_node(self, root, depth):\n",
    "        if (root is None) or (root.left is None) or (root.right is None):\n",
    "            return\n",
    "        if root.classASize == 0:\n",
    "            return\n",
    "        if root.classBSize == 0:\n",
    "            return\n",
    "        if (root.classASize + root.classBSize) < self.min_samples_split:\n",
    "            return\n",
    "        if root.score == -1:\n",
    "            return\n",
    "        \n",
    "        if depth > self.max_depth:\n",
    "            return;\n",
    "        \n",
    "        root.left = self.add_node(self.best_split(root.left.df), depth + 1)\n",
    "        root.right = self.add_node(self.best_split(root.right.df), depth + 1)\n",
    "        return root;\n",
    "    \n",
    "    # train adaboost model\n",
    "    def train_adaboost(self, train_adaboost_data, k_stumps):        \n",
    "        target_feat_vals = train_adaboost_data[self.target_feature].unique()\n",
    "        target_feat_vals.sort()\n",
    "        \n",
    "        filtered_class_byTarget = train_adaboost_data[self.target_feature].value_counts()\n",
    "        stump = BinaryTree(filtered_class_byTarget[target_feat_vals[0]],filtered_class_byTarget[target_feat_vals[1]], None, None, None, train_adaboost_data, None)\n",
    "        stump.root = self.best_split(stump.root.df)\n",
    "\n",
    "        # store all stumps with their amount of say\n",
    "        stumps_amount_of_say = {}\n",
    "\n",
    "        #create k stumps\n",
    "        for k in range(0, k_stumps):\n",
    "            tmp_df = stump.root.df.copy()\n",
    "            #inital weight\n",
    "            tmp_df[\"SampleWeight\"] = 1 / len(tmp_df.index)\n",
    "        \n",
    "            #performance say\n",
    "            perf_say = calcPerformanceSay(stump.root)\n",
    "            \n",
    "            # calculate the new sample weights for each stump\n",
    "            for i in range(train_adaboost_data.index[0], train_adaboost_data.index[-1]):\n",
    "                dff = tmp_df.loc[i:i, :]\n",
    "                output = self.test_tree(stump.root, dff)\n",
    "                if output == dff.iloc[0][self.target_feature]:\n",
    "                    prev_weight = tmp_df.at[i,'SampleWeight']\n",
    "                    tmp_df.at[i,'SampleWeight'] = prev_weight * pow(np.exp(1), -1 * perf_say)\n",
    "                else:\n",
    "                    prev_weight = tmp_df.at[i,'SampleWeight']\n",
    "                    tmp_df.at[i,'SampleWeight'] = prev_weight * pow(np.exp(1), perf_say)\n",
    "        \n",
    "            # normalize Sample Weight column\n",
    "            tmp_df[\"SampleWeight\"] = tmp_df[\"SampleWeight\"] / sum(tmp_df[\"SampleWeight\"])\n",
    "            new_df = tmp_df.copy()\n",
    "            \n",
    "            sel_col = new_df[[\"SampleWeight\"]]\n",
    "            res = sel_col.cumsum(axis = 0)\n",
    "            \n",
    "            # fill the new dataframe with new data from the old dataframe\n",
    "            for i in range(train_adaboost_data.index[0], train_adaboost_data.index[-1]):\n",
    "                rand = random.uniform(0, 1)\n",
    "                #cur_sum = 0\n",
    "                row_index = res[res['SampleWeight'].gt(rand)].index[0]\n",
    "                new_df.loc[i] = tmp_df.loc[row_index]\n",
    "\n",
    "                    \n",
    "            del new_df['SampleWeight']\n",
    "\n",
    "            stumps_amount_of_say[stump.root] = perf_say\n",
    "                \n",
    "            filtered_class_byTarget = new_df[self.target_feature].value_counts()\n",
    "            stump.root.df = new_df\n",
    "            stump.classASize = filtered_class_byTarget[target_feat_vals[0]]\n",
    "            stump.classBSize = filtered_class_byTarget[target_feat_vals[1]]\n",
    "            stump.root = self.best_split(stump.root.df)\n",
    "            \n",
    "        return stumps_amount_of_say\n",
    "  \n",
    "\n",
    "    # test AdaBoost Model\n",
    "    def test_adaboost(self, stumps_amounts_ofSay, test_data):\n",
    "        counter_true = 0\n",
    "        counter_false = 0\n",
    "        \n",
    "        target_feat_vals = data[self.target_feature].unique()\n",
    "        target_feat_vals.sort()\n",
    "        \n",
    "        tp = 0\n",
    "        fn = 0\n",
    "        fp = 0\n",
    "        tn = 0\n",
    "            \n",
    "        for i in range(test_data.index[0], test_data.index[-1]):\n",
    "            sum_say_true = 0\n",
    "            sum_say_false = 0\n",
    "            result = None\n",
    "            #calculate sum of true and false amount of say for each row\n",
    "            for k,v in stumps_amounts_ofSay.items():\n",
    "                dff = test_data.loc[i:i, :]\n",
    "                output = self.test_tree(k, dff)\n",
    "                if output == target_feat_vals[0]:\n",
    "                    sum_say_true = sum_say_true + v\n",
    "                else:\n",
    "                    sum_say_false = sum_say_false + v\n",
    "     \n",
    "            # decide to which class the row is classified\n",
    "            if sum_say_true > sum_say_false:\n",
    "                result = target_feat_vals[0]\n",
    "            else:\n",
    "                result = target_feat_vals[1]\n",
    "    \n",
    "            dff2 = test_data.loc[i:i, :]\n",
    "\n",
    "            # check the actual class of the current row\n",
    "            if result == dff2.iloc[0][self.target_feature]:\n",
    "                counter_true = counter_true + 1\n",
    "            else:\n",
    "                counter_false = counter_false + 1\n",
    "            \n",
    "            # Sensitivity & Specificity\n",
    "            if result == target_feat_vals[0]:\n",
    "                if result == dff.iloc[0][self.target_feature]:\n",
    "                    tp = tp + 1\n",
    "                else:\n",
    "                    fp = fp + 1\n",
    "            else:\n",
    "                if result == dff.iloc[0][self.target_feature]:\n",
    "                    tn = tn + 1\n",
    "                else:\n",
    "                    fn = fn + 1\n",
    "\n",
    "        \n",
    "        print(\"tp: \" + str(tp))\n",
    "        print(\"fn: \" + str(fn))\n",
    "        print(\"fp: \" + str(fp))\n",
    "        print(\"tn: \" + str(tn))\n",
    "\n",
    "        print(\"Sensitivity: \" + str(tp / (tp + fn)))\n",
    "        print(\"Specificity: \" + str(tn / (tn + fp)))\n",
    "        print(\"Accuracy: \" + str((tp + tn) / (tp + tn + fp + fn)))\n",
    "\n",
    " \n",
    "        return counter_true / (counter_true + counter_false)\n",
    "    \n",
    "    def validate_adaboost(self, parms_list, val_data):\n",
    "        iterations_num = []\n",
    "        iterations_acc = []\n",
    "        acc = 0\n",
    "        best_k = 0\n",
    "        for k in range(parms_list[\"k_stumps\"][0], parms_list[\"k_stumps\"][1] + 10, 10):\n",
    "            iterations_num.append(k)\n",
    "            print(\"k: \" + str(k))\n",
    "            stumps_amount_ofSay = self.train_adaboost(val_data, k)\n",
    "            cur_acc = self.test_adaboost(stumps_amount_ofSay, val_data)\n",
    "            iterations_acc.append(cur_acc)\n",
    "            if acc < cur_acc:\n",
    "                acc = cur_acc\n",
    "                best_k = k\n",
    "        \n",
    "        plt.plot(iterations_num, iterations_acc, color='red', marker='o')\n",
    "        plt.title('Accuracy Vs Number Of Stumps')\n",
    "        plt.xlabel('Stumps Number')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "        return best_k\n",
    "        \n",
    "        \n",
    "    # train and test the Classification Tree Model\n",
    "    def train_test_model(self, df, train_data, test_data):\n",
    "        #train_data = df.loc[:8040, :]\n",
    "        \n",
    "        filtered_class_byTarget = train_data[self.target_feature].value_counts()\n",
    "        \n",
    "        # get categorical values of target feature\n",
    "        target_feat_vals = data[self.target_feature].unique()\n",
    "        target_feat_vals.sort()\n",
    "        \n",
    "        #initalize tree parameters with the original training data\n",
    "        tree = BinaryTree(filtered_class_byTarget[target_feat_vals[0]],filtered_class_byTarget[target_feat_vals[1]], None, None, None, train_data, None)\n",
    "   \n",
    "        #Inital tree to start with\n",
    "        tree.root = self.best_split(tree.root.df)\n",
    "        \n",
    "        #call the best_split function to create the whole tree and return the root of that tree\n",
    "        class_tree = self.add_node(tree.root, 0)\n",
    "        \n",
    "        tp = 0\n",
    "        fn = 0\n",
    "        fp = 0\n",
    "        tn = 0\n",
    "        # Sensitivity & Specificity\n",
    "        for i in range(test_data.index[0], test_data.index[-1]):\n",
    "            dff = data.loc[i:i, :]\n",
    "            output = self.test_tree(class_tree, dff)\n",
    "            if output == target_feat_vals[0]:\n",
    "                if output == dff.iloc[0][self.target_feature]:\n",
    "                    tp = tp + 1\n",
    "                else:\n",
    "                    fp = fp + 1\n",
    "            else:\n",
    "                if output == dff.iloc[0][self.target_feature]:\n",
    "                    tn = tn + 1\n",
    "                else:\n",
    "                    fn = fn + 1\n",
    "\n",
    "        \n",
    "        print(\"tp: \" + str(tp))\n",
    "        print(\"fn: \" + str(fn))\n",
    "        print(\"fp: \" + str(fp))\n",
    "        print(\"tn: \" + str(tn))\n",
    "\n",
    "        print(\"Sensitivity: \" + str(tp / (tp + fn)))\n",
    "        print(\"Specificity: \" + str(tn / (tn + fp)))\n",
    "        print(\"Accuracy: \" + str((tp + tn) / (tp + tn + fp + fn)))\n",
    "\n",
    "        return (tp + tn) / (tp + tn + fp + fn)\n",
    "        \n",
    "    # this function validates the model with given hyper-parameters\n",
    "    def validate_model(self, df, parms_list, validation_data):\n",
    "        #validation_data = df.loc[8041:10050, :]\n",
    "        max_depth = 0\n",
    "        best_acc = 0\n",
    "        depths = []\n",
    "        depth_acc = []\n",
    "        for i in range(parms_list[\"max_depth\"][0], parms_list[\"max_depth\"][1] + 1):\n",
    "            depths.append(i)\n",
    "            self.max_depth = i\n",
    "        \n",
    "            filtered_class_byTarget = validation_data[self.target_feature].value_counts()\n",
    "        \n",
    "            # get categorical values of target feature\n",
    "            target_feat_vals = data[self.target_feature].unique()\n",
    "            target_feat_vals.sort()\n",
    "            \n",
    "            tree = BinaryTree(filtered_class_byTarget[target_feat_vals[0]],filtered_class_byTarget[target_feat_vals[1]], None, None, None, df, None)\n",
    "        \n",
    "            tree.root = self.best_split(tree.root.df)\n",
    "        \n",
    "            test = self.add_node(tree.root, 0)\n",
    "        \n",
    "            counter_true = 0\n",
    "            counter_false = 0\n",
    "        \n",
    "            for j in range(validation_data.index[0], validation_data.index[-1]):\n",
    "                dff = data.loc[j:j, :]\n",
    "                output = self.test_tree(test, dff)\n",
    "                if output == dff.iloc[0][self.target_feature]:\n",
    "                    counter_true = counter_true + 1\n",
    "                else:\n",
    "                    counter_false = counter_false + 1\n",
    "        \n",
    "            cur_acc = counter_true / (counter_true + counter_false)\n",
    "            if cur_acc > best_acc:\n",
    "                best_acc = cur_acc\n",
    "                max_depth = i\n",
    "                \n",
    "            depth_acc.append(cur_acc)\n",
    "        \n",
    "        plt.plot(depths, depth_acc, color='red', marker='o')\n",
    "        plt.title('Accuracy Vs Tree Depth')\n",
    "        plt.xlabel('Depth')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        return max_depth\n",
    "    \n",
    "    # this function returns the output for each given row\n",
    "    def test_tree(self, root, row):\n",
    "        while(root.left is not None and root.right is not None):\n",
    "            tmp = row[root.feature].tolist()\n",
    "            tmp.sort()\n",
    "            if self.features[root.feature]:\n",
    "                if tmp[0] == root.left.pathValue1:\n",
    "                    root = root.left\n",
    "                else:\n",
    "                    root = root.right\n",
    "            else:   \n",
    "                if tmp[0] < root.pathValue2:\n",
    "                    root = root.left\n",
    "                else:\n",
    "                    root = root.right\n",
    "\n",
    "        \n",
    "        target_feat_vals = data[self.target_feature].unique()\n",
    "        target_feat_vals.sort()\n",
    "        if root.classASize > root.classBSize:\n",
    "            return target_feat_vals[0]\n",
    "        else:\n",
    "            return target_feat_vals[1]\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80ccbbd",
   "metadata": {},
   "source": [
    "### Classification Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0870faf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True = Categorical, False = Continuous\n",
    "target_feat = \"area_type\"\n",
    "features_list = {\"bedrooms\":False, \"price in rupees\":False, \"ranked\":False, \"total_sqft\":False, \"balcony\":False, \"bath\":False, \"availability\":True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1c3347a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cls_train = data.loc[:8040, :]\n",
    "X_cls_validate = data.loc[8041:10050, :]\n",
    "X_cls_test = data.loc[10051:12563, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378e1637",
   "metadata": {},
   "source": [
    "### Define The Decision Tree Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8b0ee20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_model = classification_Tree(6, 2, target_feat, features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce536033",
   "metadata": {},
   "source": [
    "### Fit The Decsion Tree Model\n",
    "### Note: Only Max Depth Can Be Tuned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b14c2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameter grid\n",
    "parameters_grid = {\n",
    "    'max_depth': [2, 10],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b69fb829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_best_depth = class_model.validate_model(X_cls_train, parameters_grid, X_cls_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26c9d51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_best_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df96f450",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_model.max_depth = class_best_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ec8b8d",
   "metadata": {},
   "source": [
    "### Predict And Evaluate The Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e59a56ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 6706\n",
      "fn: 150\n",
      "fp: 437\n",
      "tn: 747\n",
      "Sensitivity: 0.9781213535589265\n",
      "Specificity: 0.6309121621621622\n",
      "Accuracy: 0.9269900497512438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9269900497512438"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the bias of the model\n",
    "class_model.train_test_model(data, X_cls_train, X_cls_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72f82c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 2068\n",
      "fn: 93\n",
      "fp: 145\n",
      "tn: 205\n",
      "Sensitivity: 0.956964368347987\n",
      "Specificity: 0.5857142857142857\n",
      "Accuracy: 0.9052170450019913\n"
     ]
    }
   ],
   "source": [
    "# check the actual accuracy of the model using new test data\n",
    "dt_accuracy = class_model.train_test_model(data, X_cls_train, X_cls_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f880f40e",
   "metadata": {},
   "source": [
    "### Section D Answer: We can see that we got a pretty high score for Sensitivity compared to Specificity which has a low score,  \"A highly sensitive test means that there are few false negative results, and thus fewer cases of the predicted feature are missed\", meanwhile \"A test with low specificity can be thought of as being too eager to find a positive result, even when it is not present, and may give a high number of false positives.\"\n",
    "### So long story short we need to lower the number of fp cases in our model, but how do we do that? Since our categorical features do not have a definitive class which is true or false the Sensitivity and Specificity values could be swapped then we get a high Specificity but low Sensitivity, in other words there is a tradeoff between the tow metrics, but if we want to get both metrics to return high values our model must return less fp and fn values, a suggested method to solve this problem would be to use the ROC Curve to determine the best cut-off for tp and fp cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f2adf9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9052170450019913"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63edb3c",
   "metadata": {},
   "source": [
    "### Fit AdaBoost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2417bf",
   "metadata": {},
   "source": [
    "### Note: Only Number Of Iterations Can Be Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "943204a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameter grid for AdaBoost Validation\n",
    "param_grid_ada = {\n",
    "    'k_stumps': [50, 100],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59c09ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 50\n",
      "tp: 1624\n",
      "fn: 84\n",
      "fp: 133\n",
      "tn: 168\n",
      "Sensitivity: 0.9508196721311475\n",
      "Specificity: 0.5581395348837209\n",
      "Accuracy: 0.89198606271777\n",
      "k: 60\n",
      "tp: 1615\n",
      "fn: 93\n",
      "fp: 131\n",
      "tn: 170\n",
      "Sensitivity: 0.9455503512880562\n",
      "Specificity: 0.5647840531561462\n",
      "Accuracy: 0.8885017421602788\n",
      "k: 70\n",
      "tp: 1623\n",
      "fn: 85\n",
      "fp: 125\n",
      "tn: 176\n",
      "Sensitivity: 0.9502341920374707\n",
      "Specificity: 0.584717607973422\n",
      "Accuracy: 0.8954703832752613\n",
      "k: 80\n",
      "tp: 1501\n",
      "fn: 207\n",
      "fp: 102\n",
      "tn: 199\n",
      "Sensitivity: 0.8788056206088993\n",
      "Specificity: 0.6611295681063123\n",
      "Accuracy: 0.8461921353907417\n",
      "k: 90\n",
      "tp: 1630\n",
      "fn: 78\n",
      "fp: 148\n",
      "tn: 153\n",
      "Sensitivity: 0.9543325526932084\n",
      "Specificity: 0.5083056478405316\n",
      "Accuracy: 0.8875062220009955\n",
      "k: 100\n",
      "tp: 1653\n",
      "fn: 55\n",
      "fp: 131\n",
      "tn: 170\n",
      "Sensitivity: 0.9677985948477752\n",
      "Specificity: 0.5647840531561462\n",
      "Accuracy: 0.90741662518666\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_k = class_model.validate_adaboost(param_grid_ada, X_cls_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a377556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a8ad5b",
   "metadata": {},
   "source": [
    "### Predict And Evaluate Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09c287f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stumps_amounts_ofSay = class_model.train_adaboost(X_cls_train, best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad636b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 6634\n",
      "fn: 222\n",
      "fp: 585\n",
      "tn: 599\n",
      "Sensitivity: 0.9676196032672112\n",
      "Specificity: 0.5059121621621622\n",
      "Accuracy: 0.8996268656716417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8996268656716417"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the bias of the model\n",
    "class_model.test_adaboost(stumps_amounts_ofSay, X_cls_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2be0db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 2060\n",
      "fn: 101\n",
      "fp: 172\n",
      "tn: 178\n",
      "Sensitivity: 0.9532623785284591\n",
      "Specificity: 0.5085714285714286\n",
      "Accuracy: 0.8912783751493429\n"
     ]
    }
   ],
   "source": [
    "# check the actual accuracy of the model using new test data\n",
    "adaboost_acc = class_model.test_adaboost(stumps_amounts_ofSay, X_cls_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddfda86",
   "metadata": {},
   "source": [
    "### Section D Answer: The Same as Decision Tree..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3c56558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8912783751493429"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66a6597",
   "metadata": {},
   "source": [
    "### Conclusion: Observing the results we can see that our Decision Tree and Adaboost models have low bias and low variance which means they neither overfit or underfit the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0ad30a",
   "metadata": {},
   "source": [
    "# Regression Tree <a class=\"anchor\" id=\"section1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102169d4",
   "metadata": {},
   "source": [
    "### SSR Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c27aaa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_SSR(left_node, right_node, target_feat):\n",
    "    left_df = left_node.df\n",
    "    right_df = right_node.df\n",
    "    \n",
    "    left_avg = left_df[target_feat].mean()\n",
    "    right_avg = right_df[target_feat].mean()\n",
    "    \n",
    "    left_col_target = left_df[target_feat]\n",
    "    right_col_target = right_df[target_feat]\n",
    "    \n",
    "    ssr = 0\n",
    "    \n",
    "    for cellVal in left_col_target.values:\n",
    "        ssr = ssr + pow((cellVal - left_avg), 2)\n",
    "        \n",
    "    for cellVal in right_col_target.values:\n",
    "        ssr = ssr + pow((cellVal - right_avg), 2)\n",
    "\n",
    "    return ssr\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b44a4b",
   "metadata": {},
   "source": [
    "### Leaf Node Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46ab2123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_leafNode_avg(node, target_feat):\n",
    "    node_df = node.df\n",
    "    node_avg = node_df[target_feat].mean()\n",
    "\n",
    "    return node_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464a3985",
   "metadata": {},
   "source": [
    "### Regression Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7218a443",
   "metadata": {},
   "outputs": [],
   "source": [
    "class regression_Tree(object):  \n",
    "    def __init__(self, max_depth = None, min_samples_split = 2, target_feature = None, features = None):\n",
    "        self.max_depth = 6 if max_depth is None else max_depth\n",
    "        self.min_samples_split = 2 if min_samples_split is None else min_samples_split\n",
    "        self.target_feature = None if target_feature is None else target_feature\n",
    "        self.features = features\n",
    " \n",
    "    # get best split base on lowest SSR value\n",
    "    def best_split(self, df):  \n",
    "        main_tree = BinaryTree(None, None, None, None, None, None, None)\n",
    "\n",
    "        ssr_list = {}\n",
    "        \n",
    "        target_feat_vals = data[self.target_feature].unique()\n",
    "        target_feat_vals.sort()\n",
    "        \n",
    "        # iterate over the features to get their lowest SSR value\n",
    "        for feature in list(self.features.keys()):\n",
    "            tree = BinaryTree(None,None, None, None, None, None, feature)\n",
    "            mini_df = df.loc[:, [self.target_feature, feature]]\n",
    "            if self.features[feature]:\n",
    "                \n",
    "                feat_vals = df[feature].unique()\n",
    "                feat_vals.sort()\n",
    "                \n",
    "                if len(feat_vals) < 2:\n",
    "                    continue\n",
    "\n",
    "                if (mini_df[(mini_df[feature] == feat_vals[0])]).empty or (mini_df[(mini_df[feature] == feat_vals[1])]).empty:\n",
    "                    continue\n",
    "                \n",
    "                df_filtered_classA = mini_df[(mini_df[feature] == feat_vals[0])]\n",
    "                df_filtered_classB = mini_df[(mini_df[feature] == feat_vals[1])] \n",
    "                \n",
    "                count_row_A = df_filtered_classA.shape[0]\n",
    "                count_row_B = df_filtered_classB.shape[0]\n",
    "                \n",
    "                tree.root.left = Node(count_row_A, None, None, None, None, df_filtered_classA, feature)\n",
    "                tree.root.right = Node(count_row_B, None, None, None, None, df_filtered_classB, feature)\n",
    "            \n",
    "                if feature not in ssr_list:\n",
    "                    ssr_list[feature] = list()\n",
    "                    ssr_list[feature].extend([calc_SSR(tree.root.left, tree.root.right, self.target_feature)])\n",
    "\n",
    "            else:\n",
    "                selected_col = df.loc[:, feature]\n",
    "                unique_vals = selected_col.unique()\n",
    "                sorted_vals = np.sort(unique_vals)\n",
    "                avg_list = consecutive_avgs(sorted_vals)\n",
    "                continuous_ssr_list = {}\n",
    "                 \n",
    "                if len(avg_list) > 0:     \n",
    "                    for i in avg_list:   \n",
    "                        if (mini_df[(mini_df[feature] < i)]).empty or (mini_df[(mini_df[feature] > i)]).empty:\n",
    "                            continue\n",
    "                \n",
    "                        df_filtered_classA = mini_df[(mini_df[feature] < i)]\n",
    "                        df_filtered_classB = mini_df[(mini_df[feature] > i)]\n",
    "                        \n",
    "                        count_row_A = df_filtered_classA.shape[0]\n",
    "                        count_row_B = df_filtered_classB.shape[0]\n",
    "            \n",
    "                        tree.root.left = Node(count_row_A, None, None, None, None, df_filtered_classA, feature)\n",
    "                        tree.root.right = Node(count_row_B, None, None, None, None, df_filtered_classB, feature)\n",
    "   \n",
    "                        continuous_ssr_list[i] = calc_SSR(tree.root.left, tree.root.right, self.target_feature)\n",
    "        \n",
    "                    min_ssr_index = min(continuous_ssr_list, key=continuous_ssr_list.get)\n",
    "\n",
    "                    if feature not in ssr_list:\n",
    "                        ssr_list[feature] = list()\n",
    "                        ssr_list[feature].extend([min_ssr_index, continuous_ssr_list[min_ssr_index]])\n",
    "\n",
    "        min_ssr = None\n",
    "        min_ssr_feature = None\n",
    "        \n",
    "        # get the lowest SSR value with its feature\n",
    "        for k, v in ssr_list.items():\n",
    "            if not self.features[k]:\n",
    "                if min_ssr != None:\n",
    "                    if v[1] < min_ssr:\n",
    "                        min_ssr = v[1]\n",
    "                        min_ssr_feature = k\n",
    "                else:\n",
    "                    min_ssr = v[1]\n",
    "                    min_ssr_feature = k\n",
    "            else:\n",
    "                if min_ssr != None:\n",
    "                    if v[0] < min_ssr:\n",
    "                        min_ssr = v[0]\n",
    "                        min_ssr_feature = k\n",
    "                else:\n",
    "                    min_ssr = v[0]\n",
    "                    min_ssr_feature = k\n",
    "        \n",
    "\n",
    "        if (min_ssr is None) or (min_ssr_feature is None):\n",
    "            return None\n",
    "                \n",
    "        # build the root with its left and right nodes base on the best feature we found earlier\n",
    "        if self.features[min_ssr_feature]:\n",
    "            count_row = df.shape[0]\n",
    "            feat_vals = df[min_ssr_feature].unique()\n",
    "            feat_vals.sort()\n",
    "            \n",
    "            if (feat_vals[0] is None) or (feat_vals[1] is None):\n",
    "                return None\n",
    "            \n",
    "            main_tree.root = Node(count_row, None, feat_vals[0], feat_vals[1], ssr_list[min_ssr_feature][0], df, min_ssr_feature)\n",
    "           \n",
    "            father_df = main_tree.root.df\n",
    "            if (father_df[father_df[main_tree.root.feature] == main_tree.root.pathValue1]).empty or (father_df[father_df[main_tree.root.feature] == main_tree.root.pathValue2]).empty:\n",
    "                return None\n",
    "            \n",
    "            leftNode_df = father_df[father_df[main_tree.root.feature] == main_tree.root.pathValue1]\n",
    "            rightNode_df = father_df[father_df[main_tree.root.feature] == main_tree.root.pathValue2]\n",
    "\n",
    "            count_row_A = leftNode_df.shape[0]\n",
    "            count_row_B = rightNode_df.shape[0]\n",
    "            \n",
    "            main_tree.root.left = Node(count_row_A, None, None, None, None, leftNode_df, None)\n",
    "            main_tree.root.right = Node(count_row_B, None, None, None, None, rightNode_df, None)\n",
    "        else:  \n",
    "            count_row = df.shape[0]\n",
    "                        \n",
    "            main_tree.root = Node(count_row, None, (-1 * ssr_list[min_ssr_feature][0]), ssr_list[min_ssr_feature][0], ssr_list[min_ssr_feature][1], df, min_ssr_feature)\n",
    "           \n",
    "            father_df = main_tree.root.df\n",
    "            if (father_df[father_df[main_tree.root.feature] < abs(main_tree.root.pathValue1)]).empty or (father_df[father_df[main_tree.root.feature] > main_tree.root.pathValue2]).empty:\n",
    "                return None\n",
    "            \n",
    "            leftNode_df = father_df[father_df[main_tree.root.feature] < abs(main_tree.root.pathValue1)]\n",
    "            rightNode_df = father_df[father_df[main_tree.root.feature] > main_tree.root.pathValue2]\n",
    "            \n",
    "            count_row_A = leftNode_df.shape[0]\n",
    "            count_row_B = rightNode_df.shape[0]\n",
    "\n",
    "            main_tree.root.left = Node(count_row_A, None, None, None, None, leftNode_df, None)\n",
    "            main_tree.root.right = Node(count_row_B, None, None, None, None, rightNode_df, None)\n",
    "   \n",
    "        return main_tree.root\n",
    "            \n",
    "    # recursively build the tree\n",
    "    def add_node(self, root, depth):\n",
    "        if (root is None) or (root.left is None) or (root.right is None):\n",
    "            return\n",
    "\n",
    "        if root.classASize < self.min_samples_split:\n",
    "            return\n",
    "        \n",
    "        if depth > self.max_depth:\n",
    "            return;\n",
    "        \n",
    "        root.left = self.add_node(self.best_split(root.left.df), depth + 1)\n",
    "        root.right = self.add_node(self.best_split(root.right.df), depth + 1)\n",
    "        return root;\n",
    "\n",
    "    #train and test the final model\n",
    "    def train_test_model(self, df, train_data, test_data):                \n",
    "        count_row = train_data.shape[0]\n",
    "\n",
    "        tree = BinaryTree(count_row,None, None, None, None, train_data, None)\n",
    "        \n",
    "        tree.root = self.best_split(tree.root.df)\n",
    "        \n",
    "        test = self.add_node(tree.root, 0)\n",
    "        \n",
    "        true_list = []\n",
    "        predicted_list = []\n",
    "        \n",
    "        # testing phase\n",
    "        for i in range(test_data.index[0], test_data.index[-1]):\n",
    "            dff = test_data.loc[i:i, :]\n",
    "            tmp = dff[self.target_feature].tolist()\n",
    "            true_list.append(tmp[0])\n",
    "            predicted_val = self.test_tree(test, dff)\n",
    "            predicted_list.append(predicted_val)\n",
    "\n",
    "        # Mean Squared Error\n",
    "        MSE = round(mean_squared_error(true_list, predicted_list), 6)\n",
    "\n",
    "        print(\"MSE: \" + str(MSE))\n",
    "        \n",
    "        return MSE\n",
    "        \n",
    "    \n",
    "    # this function validates the model with given hyper-parameters\n",
    "    def validate_model(self, df, parms_list, validation_data):        \n",
    "        #validation_data = df.loc[8041:10050, :]\n",
    "        max_depth = 0\n",
    "        best_mse = -1\n",
    "        depths = []\n",
    "        depth_mse = []\n",
    "        \n",
    "        for i in range(parms_list[\"max_depth\"][0], parms_list[\"max_depth\"][1] + 1):\n",
    "            depths.append(i)\n",
    "            self.max_depth = i\n",
    "                        \n",
    "            count_row = validation_data.shape[0]\n",
    "\n",
    "            tree = BinaryTree(count_row,None, None, None, None, df, None)\n",
    "        \n",
    "            tree.root = self.best_split(tree.root.df)\n",
    "        \n",
    "            reg_tree = self.add_node(tree.root, 0)\n",
    "        \n",
    "            true_list = []\n",
    "            predicted_list = []\n",
    "        \n",
    "            # validation phase\n",
    "            for j in range(validation_data.index[0], validation_data.index[-1]):\n",
    "                dff = validation_data.loc[j:j, :]\n",
    "                tmp = dff[self.target_feature].tolist()\n",
    "                true_list.append(tmp[0])\n",
    "                predicted_val = self.test_tree(reg_tree, dff)\n",
    "                predicted_list.append(predicted_val)\n",
    "        \n",
    "            MSE = round(mean_squared_error(true_list, predicted_list), 6)\n",
    "\n",
    "            depth_mse.append(MSE)\n",
    "            \n",
    "            if best_mse < 0:\n",
    "                best_mse = MSE\n",
    "                max_depth = i\n",
    "            if best_mse > MSE:\n",
    "                best_mse = MSE\n",
    "                max_depth = i\n",
    "            \n",
    "            \n",
    "        plt.plot(depths, depth_mse, color='red', marker='o')\n",
    "        plt.title('MSE Vs Tree Depth')\n",
    "        plt.xlabel('Depth')\n",
    "        plt.ylabel('MSE')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "        return max_depth\n",
    "    \n",
    "    # test each row and return its selected output class\n",
    "    def test_tree(self, root, row):\n",
    "        while(root.left is not None and root.right is not None):\n",
    "            tmp = row[root.feature].tolist()\n",
    "            if self.features[root.feature]:\n",
    "                if tmp[0] == root.pathValue1:\n",
    "                    root = root.left\n",
    "                else:\n",
    "                    root = root.right\n",
    "            else:   \n",
    "                if tmp[0] < root.pathValue2:\n",
    "                    root = root.left\n",
    "                else:\n",
    "                    root = root.right\n",
    "\n",
    "        return calc_leafNode_avg(root, self.target_feature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f1ee5d",
   "metadata": {},
   "source": [
    "### Regression Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89e03ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_target_feat = \"price in rupees\"\n",
    "# True = Categorical, False = Continuous\n",
    "reg_features_list = {\"bedrooms\":False, \"area_type\":True, \"ranked\":False, \"total_sqft\":False, \"balcony\":False, \"bath\":False, \"availability\":True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cc86f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cls_train = data.loc[:8040, :]\n",
    "X_cls_validate = data.loc[8041:10050, :]\n",
    "X_cls_test = data.loc[10051:12563, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc226ba6",
   "metadata": {},
   "source": [
    "### Define The Regression Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8554bf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model = regression_Tree(6, 2, reg_target_feat, reg_features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e0500c",
   "metadata": {},
   "source": [
    "### Fit The Regression Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39983c54",
   "metadata": {},
   "source": [
    "### Note: Only Max Depth Can Be Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3e4d876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameter grid\n",
    "parameters_grid = {\n",
    "    'max_depth': [2, 10],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47333332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reg_best_depth = reg_model.validate_model(X_cls_train, parameters_grid, X_cls_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5d665d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_best_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "379d30b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model.max_depth = reg_best_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8af83dd",
   "metadata": {},
   "source": [
    "### Predict And Evaluate The Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "337a2097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 37828702717182.11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "37828702717182.11"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the bias of the model\n",
    "reg_model.train_test_model(data, X_cls_train, X_cls_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "815e01a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 74405722751254.38\n"
     ]
    }
   ],
   "source": [
    "# check the actual MSE of the model using new test data\n",
    "model_mse = reg_model.train_test_model(data, X_cls_train, X_cls_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2fc7c5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74405722751254.38"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f789682a",
   "metadata": {},
   "source": [
    "### Conclusion: Observing the results we can see that our Regression Tree model has a high variance and low bias which means it overfits the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1b3df3",
   "metadata": {},
   "source": [
    "# Comparison With Sklearn Built-In Models <a class=\"anchor\" id=\"section1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de0de3d",
   "metadata": {},
   "source": [
    "### Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3ce2a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "# random forest\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "# model building\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# model evaluation\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "# set seed for reproducible results\n",
    "RSEED = 10\n",
    "\n",
    "from sklearn import preprocessing # normalizing for regression tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facb7f5b",
   "metadata": {},
   "source": [
    "### Classification Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ffc3856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cls = data[['availability', 'bedrooms', 'total_sqft', 'bath', 'balcony', 'ranked', 'price in rupees']]\n",
    "y_cls = data['area_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a221c879",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cls_train = X_cls.loc[:8040, :]\n",
    "X_cls_test = X_cls.loc[10051:12563, :]\n",
    "y_cls_train = y_cls.loc[:8040]\n",
    "y_cls_test = y_cls.loc[10051:12563]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ea5f13",
   "metadata": {},
   "source": [
    "### Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a442119b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "dt = DecisionTreeClassifier(random_state=RSEED, max_depth = class_best_depth, min_samples_split = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5634e1",
   "metadata": {},
   "source": [
    "### Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c11ce03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit estimator\n",
    "dt = dt.fit(X_cls_train,y_cls_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a41251",
   "metadata": {},
   "source": [
    "### Predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "101dfad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_cls_pred = dt.predict(X_cls_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe66151",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "82e6c5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SkLearn Accuracy</th>\n",
       "      <th>Our Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.909236</td>\n",
       "      <td>0.905217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          SkLearn Accuracy  Our Accuracy\n",
       "Decision Tree Classifier          0.909236      0.905217"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "acc = round(accuracy_score(y_cls_test, y_cls_pred), 6)\n",
    "\n",
    "df = pd.DataFrame([acc]).T\n",
    "df = df.rename(index={0: 'Decision Tree Classifier'}, columns={0: 'SkLearn Accuracy'})\n",
    "df[\"Our Accuracy\"] = dt_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d63b77b",
   "metadata": {},
   "source": [
    "### Conclusion: We got a pretty close accuracy to sklearn model with a difference of only 0.004019, a possible explanation for this difference could be the way in which sklearn implements its classifier and the number of hyper-parameters it uses, even though we gave sklearn model only the max_depth and min_samples_split hyper-parameters doesn't mean that its going to build the model based on these parameters alone instead it sets the other hyper-parameters to their default state and uses them nonetheless, so in conclusion the main reason for this difference in accuracies could be based off of the number of hyper-parameters used to build each model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ceadb26",
   "metadata": {},
   "source": [
    "### Regression Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a63f8282",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reg = data[['availability', 'bedrooms', 'total_sqft', 'bath', 'balcony', 'ranked']]\n",
    "y_reg = data['price in rupees']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58503728",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reg_train = X_reg.loc[:8040, :]\n",
    "X_reg_test = X_reg.loc[10051:12563, :]\n",
    "y_reg_train = y_reg.loc[:8040]\n",
    "y_reg_test = y_reg.loc[10051:12563]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cb0d2a",
   "metadata": {},
   "source": [
    "### Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cabc4c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "rt = DecisionTreeRegressor(max_depth = reg_best_depth, min_samples_split = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a4495b",
   "metadata": {},
   "source": [
    "### Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b655985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit estimator\n",
    "rt = rt.fit(X_reg_train,y_reg_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ada123",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e164fd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = rt.predict(X_reg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627526f6",
   "metadata": {},
   "source": [
    "### Evaluate the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fd0a7bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>Our MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree Regressor</th>\n",
       "      <td>7.661343e+13</td>\n",
       "      <td>7.440572e+13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  MSE       Our MSE\n",
       "Decision Tree Regressor  7.661343e+13  7.440572e+13"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#min_max_scaler = preprocessing.MinMaxScaler()\n",
    "#y_reg_test_norm = min_max_scaler.fit_transform(y_reg_test.values.reshape(-1,1))\n",
    "#y_pred_norm = min_max_scaler.fit_transform(y_pred.reshape(-1,1))\n",
    "# calculate MSE\n",
    "MSE = round(mean_squared_error(y_reg_test, y_pred), 6)\n",
    "\n",
    "df = pd.DataFrame([MSE]).T\n",
    "df = df.rename(index={0: 'Decision Tree Regressor'}, columns={0: 'MSE'})\n",
    "df[\"Our MSE\"] = model_mse\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c898ac86",
   "metadata": {},
   "source": [
    "### Conclusion: We got a better MSE than sklearn model , a possible explanation for this difference could be the way in which sklearn implements its regressor and the number of hyper-parameters it uses, even though we gave sklearn model only the max_depth and min_samples_split hyper-parameters doesn't mean that its going to build the model based on these parameters alone instead it sets the other hyper-parameters to their default state and uses them nonetheless, so in conclusion the main reason for this difference in MSE values could be based off of the number of hyper-parameters used to build each model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0421031a",
   "metadata": {},
   "source": [
    "# AdaBoost <a class=\"anchor\" id=\"section3\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba44e5b",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b9514dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor\n",
    "# model building\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# model evaluation\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "# set seed for reproducible results\n",
    "RSEED = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257a0ecd",
   "metadata": {},
   "source": [
    "### Classification Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "774ac6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cls_adaboost = data[['availability', 'bedrooms', 'total_sqft', 'bath', 'balcony', 'ranked', 'price in rupees']]\n",
    "y_cls_adaboost = data['area_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f94cf692",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cls_train_ada = X_cls_adaboost.loc[:8040, :]\n",
    "X_cls_test_ada = X_cls_adaboost.loc[10051:12563, :]\n",
    "y_cls_train_ada = y_cls_adaboost.loc[:8040]\n",
    "y_cls_test_ada = y_cls_adaboost.loc[10051:12563]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f119d1ea",
   "metadata": {},
   "source": [
    "### Define The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6422e627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "ab = AdaBoostClassifier(n_estimators = best_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcda46e",
   "metadata": {},
   "source": [
    "### Fit The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5407c699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit estimator\n",
    "ab = ab.fit(X_cls_train_ada, y_cls_train_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d9ab21",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5f1f92a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred_ada = ab.predict(X_cls_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f585a1b",
   "metadata": {},
   "source": [
    "### Evaluate The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2cfb1c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Our Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoost Classifier</th>\n",
       "      <td>0.903662</td>\n",
       "      <td>0.891278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  Our Accuracy\n",
       "AdaBoost Classifier  0.903662      0.891278"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "acc = round(accuracy_score(y_cls_test, y_pred_ada), 6)\n",
    "\n",
    "df = pd.DataFrame([acc]).T\n",
    "df = df.rename(index={0: 'AdaBoost Classifier'}, columns={0: 'Accuracy'})\n",
    "df[\"Our Accuracy\"] = adaboost_acc\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1877865b",
   "metadata": {},
   "source": [
    "### Conclusion: We got a pretty close accuracy to sklearn model with a difference of only 0.012384, a possible explanation for this difference could be the way in which sklearn implements its classifier and the number of hyper-parameters it uses, even though we gave sklearn model only the n_estimators hyper-parameter doesn't mean that its going to build the model based on this parameter alone instead it sets the other hyper-parameters to their default state and uses them nonetheless, so in conclusion the main reason for this difference in accuracies could be based off of the number of hyper-parameters used to build each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff877fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
